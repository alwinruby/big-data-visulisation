# Why does visualisation play an important role in big data analytics?


We can process large quantities of data and have access to many innovative techniques to support effective visualisation through the use of high performance computing (HPC), modern computer graphics (CG) and general purpose graphics processing units (GPGPUs).

**How big is big data?**

The smallest unit of data is a bit, a binary unit (1 or 0).

Grouping two bits would give us four distinct combinations: 00, 01, 10, and 11.

Grouping three bits would yield eight distinct combinations: 000, 001, 010, 011, 100, 101, 110, and 111.

A __byte__ (B) is a grouping of eight bits. This would yield 256 distinct combinations.

Do you see the pattern? In general, by adding one bit, you double the number of combinations.

For larger storage, you multiply a byte (B) by a factor of 1000 to get a kilobyte (KB), then megabyte (MB), gigabyte (GB), terabyte (TB), petabyte (PB), exabyte (EB) and zettabyte (ZB).

![](/pictures/scaling.png)

**What does this look like?**

Imagine a byte of data as being equal to one grain of rice. Now visualise a kilobyte as one cup of rice and a megabyte as 8 bags of rice.

A gigabyte would look like 3 container loads of rice bags and a terabyte would be 2 ships full of rice bags.

A petabyte of rice bags would cover Manhattan, and an exabyte would cover roughly half of Queensland, Australia. Finally, a zettabyte of rice bags would fill the Pacific Ocean.
